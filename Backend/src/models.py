"""
Request and response models used in the FastAPI routes (and in some of the implementations).
"""
import logging
import sys
from typing import List, Dict, Any, Optional, Self
from io import BytesIO
from datetime import datetime, tzinfo, UTC

from pydantic import BaseModel, field_validator, model_validator, Field, PrivateAttr


class ColoredFormatter(logging.Formatter):
    """
    Custom logging formatter that logs output colorful
    """

    # Define agent-specific colors
    AGENT_COLORS = {
        # Tool-llm
        "Tool Generator": "\x1b[31;20m",  # Dim Red
        "Tool Evaluator": "\x1b[33;20m",  # Dim Yellow
        "Output Generator": "\x1b[32;20m", # Dim Green

        # Simple Roles
        "system": "\x1b[93m",  # Light Yellow
        "assistant": "\x1b[94m",  # Light Blue
        "user": "\x1b[97m",  # Light White

        # Default
        "Default": "\x1b[38;20m",  # Dim White
    }

    def format(self, record):
        agent_name = getattr(record, "agent_name", "Default")
        color = self.AGENT_COLORS.get(agent_name, self.AGENT_COLORS["Default"])

        # Get timestamp and formatted base string
        timestamp = self.formatTime(record, "%Y-%m-%d %H:%M:%S")
        base = f"{timestamp} [{record.levelname}] {agent_name} -"

        # Split messages into lines to make colorful logging work in docker
        message_lines = record.getMessage().splitlines()
        formatted_lines = [
            f"{color}{base} {message_lines[0]}\x1b[0m",
        ] + [
            f"{color}{' ' * len(base)} {line}\x1b[0m"
            for line in message_lines[1:]
        ]

        return "\n".join(formatted_lines)


# Define a logger
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# Reduce logging level for httpx
logging.getLogger("httpx").setLevel(logging.WARNING)

# Create colorful logging handler for agent messages
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(ColoredFormatter())

# Attach handler to root logger
logger.addHandler(console_handler)


class ConnectInfo(BaseModel):
    """
    Used as payload for the `/connect` route.
    
    Attributes
        url: The base url to be used for every interaction with the OPACA  platform.
        user: OPACA platform user name (when using auth), or null
        pwd: OPACA platform password (when using auth), or null
    """
    url: str
    user: str | None
    pwd: str | None


class Message(BaseModel):
    """
    Used as the expected body argument in the `/query/{backend}` endpoints

    Attributes
        user_query: The query a user has input into the OPACA LLM ChatBot.
    """
    user_query: str


class AgentMessage(BaseModel):
    """
    Used as the standard response model each time an LLM Agent is invoked.
    It stores individual information generated by the various agents

    Attributes:
        agent: The name of the agent
        content: The content of the message generated by the agent
        tools: List of generated tool calls
        response_metadata: Metadata associated with the response including token usage
        execution_time: Time it took to execute the response
        status: Status of the agent's execution (e.g., 'Planning', 'Executing', 'Completed')
        step: Current step being executed 
    """
    agent: str
    content: str = ''
    tools: List[Dict[str, Any]] = []
    response_metadata: Dict[str, Any] = {}
    execution_time: float = .0
    formatted_output: Any = None
    status: str = ""
    step: str = ""


class Response(BaseModel):
    """
    The final response that will be sent back to the frontend. Contains a list of `AgentMessages`
    that were generated during the response generation as well as final response or error.

    Attributes:
        query: The original user query that was sent to the backend.
        agent_messages: A list of agent messages that were created during the course of the response generation.
        iterations: The total number of internal iterations that were executed before returning the final response.
        execution_time: The total execution time it took for the selected method to generate an answer.
        content: The generated response that will be shown to the user.
        error: An optional output for any error messages that were generated.
    """
    query: str = ''
    agent_messages: List[AgentMessage] = []
    iterations: int = 0
    execution_time: float = .0
    content: str = ''
    error: str = ''


class OpacaFile(BaseModel):
    """
    Represents a single uploaded PDF file.

    Attributes:
        _content: Private attribute to store binary content (not part of schema or validation)
        content_type: MIME type of the file
        file_id: ID assigned after upload
    """
    _content: BytesIO = PrivateAttr()
    content_type: str
    file_id: Optional[str] = None


class ChatMessage(BaseModel):
    """
    Model for storing chat history messages. Represents single messages that are generated
    during the invocation of the OPACA-LLM. Can be stored as a list to be given as messages
    to a model during invocation.

    Attributes:
        role: Role for the message, one of 'system', 'assistant', 'user', 'function', 'tool', or 'developer'.
        content: The content of the message.
    """
    role: str
    content: str | List[Dict[str, Any]]


class Chat(BaseModel):
    """
    Stores information about each chat.

    Attributes:
        chat_id (str): The unique ID of the chat.
        messages: Chat history (user queries and final LLM responses), used in subsequent requests.
    """
    chat_id: str
    name: str = ''
    messages: List[ChatMessage] = []
    time_created: datetime = datetime.now(tz=UTC)
    time_modified: datetime = datetime.now(tz=UTC)


class SessionData(BaseModel):
    """
    Stores relevant information regarding the session, including messages, configuration,
    client instances, API keys, and uploaded files.

    Attributes:
        chats: All the chat histories associated with the session.
        config: Configuration dictionary, one sub-dict for each method.
        opaca_client: Client instance for OPACA, for calling agent actions.
        llm_clients: Dictionary of LLM client instances.
        abort_sent: Boolean indicating whether the current interaction should be aborted.
        uploaded_files: Dictionary storing each uploaded PDF file.
        valid_until: Timestamp until session is active.
    """
    chats: Dict[str, Chat] = {}
    config: Dict[str, Any] = {}
    opaca_client: Any = None
    llm_clients: Dict[str, Any] = {}
    abort_sent: bool = False
    uploaded_files: Dict[str, OpacaFile] = {}
    valid_until: float = -1


class ConfigArrayItem(BaseModel):
    """
    Defines the schema of an array item. Mainly used in connection with `ConfigParameter`.

    Attributes
        type: The type of all the items the array contains (must all be the same)
        array_items: If the array nested (`type` is `array`) defines the data types of the items.
    """
    type: str
    array_items: 'Optional[ConfigArrayItem]' = None


class ConfigParameter(BaseModel):
    """
    A custom parameter definition for the configuration of each implemented method
    Valid types are ["integer", "number", "string", "boolean", "array", "object", "null"]

    Attributes
        type: The data type of the configuration parameter.
        required: Whether the parameter is required or not.
        default: The default value of the parameter.
        array_items: Specifies the type of the array items, if `type` is set to `array`
        description: An optional description of the parameter.
        minimum: Only for types `integer` or `number`. Defines a minimum limit for the number.
        maximum: Only for types `integer` or `number`. Defines a maximum limit for the number.
        enum: If set, defines all available values the parameter can have.
    """
    type: str
    required: bool
    default: Any
    array_items: Optional[ConfigArrayItem] = None
    description: Optional[str] = None
    minimum: Optional[int | float] = None
    maximum: Optional[int | float] = None
    enum: Optional[List[Any]] = None

    @model_validator(mode='after')
    def validate_after(self: Self) -> Self:
        """
        Uses the `@model_validator` decorator of Pydantic, to check upon initialization that various
        consistency constraints are satisfied
        """
        if self.type == 'array' and self.array_items is None:
            raise ValueError(f'ConfigParameter.array_items cannot be "None" if ConfigParameter.type is "array"')
        if self.minimum is not None and self.maximum is not None and self.maximum < self.minimum:
            raise ValueError(f'ConfigParameter.maximum has to be larger than ConfigParameter.minimum')
        if self.enum is not None and self.default not in self.enum:
            raise ValueError(f'ConfigParameter.default must be one of {self.enum}')
        if (self.minimum is not None or self.maximum is not None) and self.type not in ["integer", "number"]:
            raise ValueError(f'The fields minimum and maximum can only be set for the types "integer" or "number".')
        return self

    # noinspection PyNestedDecorators
    @field_validator('type', mode='after')
    @classmethod
    def type_validator(cls, value: str) -> str:
        """
        Checks if the given type is one of the usual basic data types.
        """
        if value not in ["integer", "number", "string", "boolean", "array", "object", "null"]:
            raise ValueError(f'Value type "{value}" is not valid')
        return value


class ConfigPayload(BaseModel):
    """
    Stores the actual values of a given configuration and the schema that is defined in `ConfigParameter`.

    Attributes
        value: Should be a JSON storing the actual values of parameters in the format `{"key": value}`
        config_schema: A JSON holding the configuration schema definition (same keys as in `value`)
    """
    value: Any
    config_schema: Dict[str, ConfigParameter]          # just 'schema' would shadow parent attribute in BaseModel


class SearchResult(BaseModel):
    chat_id: str
    chat_name: str
    message_id: int
    excerpt: str


class OpacaException(Exception):
    """
    Custom Exception class that allows to return both a user-message (shown directly in the chat bubble)
    and error message (shown when clicking on the error-marker), as well as a status code.
    """

    def __init__(self, user_message: str, error_message: str | None = None, status_code: int = 400):
        super().__init__(user_message)
        self.user_message = user_message
        self.error_message = error_message
        self.status_code = status_code
